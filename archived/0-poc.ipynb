{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157.00002108341832, -90.00001200395398, 153.00002047548332]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Proof of Concept is largely influenced by \n",
    "\n",
    "# https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb#:~:text=Tutorial,-1%20%2D%20Training%20and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset\n",
      "License(s): CC0-1.0\n",
      "sleep-health-and-lifestyle-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "mkdir: .data: File exists\n",
      "Archive:  sleep-health-and-lifestyle-dataset.zip\n",
      "  inflating: .data/Sleep_health_and_lifestyle_dataset.csv  \n"
     ]
    }
   ],
   "source": [
    "# Arbitrarily chosen dataset \n",
    "# https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset/data\n",
    "\n",
    "! kaggle datasets download uom190346a/sleep-health-and-lifestyle-dataset\n",
    "! mkdir .data\n",
    "! unzip sleep-health-and-lifestyle-dataset -d .data\n",
    "! mv .data/Sleep_health_and_lifestyle_dataset.csv .data/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cleanse_data(filepath: str) -> pd.DataFrame:\n",
    "    ''' \n",
    "    Perform basic data cleansing and load the dataset\n",
    "    '''\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    df = df.drop(['Person ID'], axis=1)\n",
    "    df['Gender'] = df['Gender'].replace({\"Male\": 0, \"Female\":1 })\n",
    "    df['BMI Category'] = df['BMI Category'].replace({\"Normal Weight\": 0, \"Normal\":0, \"Obese\": 2, \"Overweight\": 1 }) \n",
    "\n",
    "\n",
    "    for col in ['Occupation']:\n",
    "        categoricals = pd.get_dummies(df[col])\n",
    "        df[categoricals.columns.values] = categoricals \n",
    "        df = df.drop(col, axis=1)\n",
    "        \n",
    "    \n",
    "    df['Systolic'] = df['Blood Pressure'].str[:3].astype(int)\n",
    "    df['Diastolic'] = df['Blood Pressure'].str[4:].astype(int)\n",
    "    df = df.drop('Blood Pressure', axis=1)\n",
    "    \n",
    "    # Assuming the target is sleep disorder and make it \"easier\" by converting it to a binary problem\n",
    "\n",
    "    df['Sleep Disorder'] = df['Sleep Disorder'].replace({\"Sleep Apnea\": 1, \"Insomnia\": 1, np.nan: 0}) \n",
    "    # x = df.drop('Sleep Disorder', axis=1).to_numpy().reshape((374, 1, 23))\n",
    "    # y = df['Sleep Disorder'].to_numpy().reshape(374, 1, 1)\n",
    "    x = df.drop('Sleep Disorder', axis=1)\n",
    "    y = df['Sleep Disorder']\n",
    "    \n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_and_cleanse_data('.data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_as_tensors(X1, X2, y1, y2) -> pd.DataFrame:\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # X1 = scaler.fit_transform(X1).reshape((X1.shape[0], 8, X1.shape[1]))\n",
    "    # X2 = scaler.transform(X2).reshape((X2.shape[0], 8, X2.shape[1]))\n",
    "    X1 = scaler.fit_transform(X1)\n",
    "    X2 = scaler.transform(X2)\n",
    "    \n",
    "    X1 = torch.tensor(X1).type(torch.float32)\n",
    "    X2 = torch.tensor(X2).type(torch.float32)\n",
    "    y1 = torch.tensor(y1.values).type(torch.float32).reshape(-1, 1)\n",
    "    y2 = torch.tensor(y2.values).type(torch.float32).reshape(-1, 1)\n",
    "\n",
    "    return X1, X2, y1, y2, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler = process_as_tensors(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([336, 1])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.fc1(X)\n",
    "        X = self.sigmoid(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(lr.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6398484110832214\n",
      "epoch 0:\n",
      "   acc: 0.7380952380952381\n",
      "   acc: 0.7368421052631579\n",
      "loss: 0.6398444175720215\n",
      "epoch 1:\n",
      "   acc: 0.7380952380952381\n",
      "   acc: 0.7368421052631579\n",
      "loss: 0.6398404240608215\n",
      "epoch 2:\n",
      "   acc: 0.7380952380952381\n",
      "   acc: 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = lr(X_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    print(f\"loss: {loss}\")\n",
    "\n",
    "    print(f\"epoch {epoch}:\")\n",
    "    print(f\"   acc: {accuracy_score(output.greater_equal_(0.5).detach().numpy(), y_train.detach().numpy())}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = lr(X_test)\n",
    "        print(f\"   acc: {accuracy_score(output.greater_equal_(0.5).detach().numpy(), y_test.detach().numpy())}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well, probably should've chosen a better dataset. Oh well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR HE Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        # TenSEAL processes lists and not torch tensors,\n",
    "        # so we take out the parameters from the PyTorch model\n",
    "        self.weight = torch_lr.fc1.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.fc1.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        # We don't need to perform sigmoid as this model\n",
    "        # will only be used for evaluation, and the label\n",
    "        # can be deduced without applying sigmoid\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "        \n",
    "    ################################################\n",
    "    ## You can use the functions below to perform ##\n",
    "    ## the evaluation with an encrypted model     ##\n",
    "    ################################################\n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        # so we are converting the weight tensors and convert them into ckks \n",
    "        # and the list was only specifically to fit in the parameters? \n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "\n",
    "eelr = EncryptedLR(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 22])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 22])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3641e-01, -5.6711e-01,  4.6299e-01,  4.9486e-01, -2.9956e-01,\n",
       "         -5.9192e-01,  5.2629e-01,  1.7862e+00, -6.7975e-01, -1.3454e-01,\n",
       "         -2.1508e-01, -7.3722e-01, -8.0552e-01,  6.1498e-01,  5.4123e-01,\n",
       "         -1.1277e+00,  1.7478e-01, -1.3616e+00,  1.2678e-01, -4.2391e-01,\n",
       "         -1.2895e+00, -9.9172e-03],\n",
       "        [-2.1464e-01, -4.3575e-01,  2.4720e-01,  4.4451e-01, -6.3491e-01,\n",
       "          1.7685e-01, -4.7589e-01, -5.2195e-01,  5.5054e-02, -1.8185e-01,\n",
       "          4.2141e-01,  6.6605e-02,  2.7149e-01,  9.2102e-02, -1.3754e+00,\n",
       "          2.7931e-01, -5.5941e-01,  5.5787e-01,  9.5676e-02, -4.5596e-01,\n",
       "          5.8295e-01, -4.6271e-01],\n",
       "        [-1.3929e-01,  1.2786e-04,  6.5116e-01,  4.9737e-01,  3.2150e-01,\n",
       "          2.6077e-01,  9.8190e-03, -6.4887e-01, -5.9816e-02, -3.0688e-01,\n",
       "         -4.1849e-01, -6.7768e-01,  1.3161e-01, -1.4912e-01, -3.7672e-01,\n",
       "          3.5482e-01, -2.0735e-01, -3.8464e-02,  4.1330e-01,  4.2140e-01,\n",
       "          2.7222e-01, -1.2028e-01],\n",
       "        [-2.0580e-03, -1.1088e+00, -6.5366e-01, -6.5334e-01,  4.6155e-01,\n",
       "          7.0868e-02, -2.9477e-01,  1.1201e+00, -4.7335e-01, -1.5451e-01,\n",
       "          2.6596e-01, -1.2743e-01, -6.6773e-01,  8.0917e-01,  1.3599e-01,\n",
       "         -4.9394e-01,  9.5916e-02, -6.1273e-02, -2.5731e-01, -8.7875e-01,\n",
       "          2.3770e-02,  4.8949e-01],\n",
       "        [-2.0580e-03, -1.1088e+00, -6.5366e-01, -6.5334e-01,  4.6155e-01,\n",
       "          7.0868e-02, -2.9477e-01,  1.1201e+00, -4.7335e-01, -1.5451e-01,\n",
       "          2.6596e-01, -1.2743e-01, -6.6773e-01,  8.0917e-01,  1.3599e-01,\n",
       "         -4.9394e-01,  9.5916e-02, -6.1273e-02, -2.5731e-01, -8.7875e-01,\n",
       "          2.3770e-02,  4.8949e-01],\n",
       "        [-1.3246e-01, -3.7786e-01,  6.7008e-01,  2.8158e-01, -8.4618e-01,\n",
       "         -5.3506e-01, -5.8998e-01,  2.8353e-01, -3.5761e-01, -4.9124e-01,\n",
       "          5.8171e-01, -9.5922e-02, -5.3809e-01, -3.0202e-01, -5.7820e-01,\n",
       "         -2.2775e-01, -1.8392e-01, -5.1942e-01,  1.9386e-01, -2.5586e-01,\n",
       "          1.5144e-01, -4.4750e-01],\n",
       "        [-3.0181e-02, -7.8368e-02,  6.2021e-01, -6.5854e-01,  2.5301e-01,\n",
       "         -5.8874e-01,  6.0442e-02,  4.8148e-01, -1.4388e-01,  3.0645e-01,\n",
       "         -3.4221e-01,  3.4456e-01, -9.7237e-01,  6.0222e-02, -1.0613e-01,\n",
       "         -1.8438e-01, -4.7609e-01, -1.0892e+00, -6.0273e-01, -1.4608e-01,\n",
       "         -6.8011e-02,  6.2835e-01],\n",
       "        [-3.6150e-01, -7.4770e-01,  2.5094e-01,  4.4115e-01, -1.1565e+00,\n",
       "         -3.7381e-01, -7.5163e-01, -5.1987e-01, -1.7363e-01, -2.3581e-01,\n",
       "          6.4792e-01, -8.7842e-02,  2.6924e-02, -2.1018e-01, -1.6361e+00,\n",
       "         -2.4080e-02, -3.6929e-01,  3.8162e-01,  2.2571e-01, -7.9775e-01,\n",
       "          7.2981e-01, -8.0651e-01],\n",
       "        [ 3.6285e-01,  5.5637e-01, -8.5519e-02, -3.2697e-01,  1.7632e-02,\n",
       "         -5.0818e-01,  3.3579e-01, -7.2102e-01,  2.4675e-01,  3.2212e-01,\n",
       "          3.4559e-01,  8.3615e-01,  1.8868e-01, -1.6577e+00,  1.0434e-01,\n",
       "         -8.6999e-03, -6.1284e-02,  2.6130e-01, -5.4717e-01,  1.0816e-02,\n",
       "          1.8895e-01, -5.3108e-01],\n",
       "        [-4.1423e-02, -1.0377e-01, -8.6186e-02,  5.8658e-02,  1.9411e-02,\n",
       "          4.2224e-02,  4.8644e-01,  7.5264e-01,  2.6507e-01,  2.8325e-01,\n",
       "         -1.3080e+00, -3.9576e-01,  8.5482e-02,  1.8627e+00,  3.8794e-01,\n",
       "          7.5955e-02,  5.8878e-01, -5.6362e-01, -2.6494e-01,  5.6461e-01,\n",
       "         -8.0084e-01,  4.4400e-01],\n",
       "        [ 3.9135e-01,  7.6881e-01,  1.9605e-01, -1.9132e-01,  5.5668e-01,\n",
       "          2.8876e-01,  1.0064e+00,  5.8345e-01,  1.9784e-01,  6.8363e-01,\n",
       "         -4.3920e-01, -1.1241e-02,  7.9202e-02, -2.4009e-01,  1.3386e+00,\n",
       "         -5.8352e-02,  2.8645e-01, -6.9726e-01, -5.1424e-01,  4.2949e-01,\n",
       "         -1.3753e+00,  7.4058e-01],\n",
       "        [ 4.1364e-01,  7.9887e-01,  2.3241e-01, -1.6134e-01,  5.3616e-01,\n",
       "          2.5008e-01,  9.7372e-01,  6.2463e-01,  2.1071e-01,  6.5542e-01,\n",
       "         -4.6594e-01, -4.4876e-02,  6.4033e-02, -2.2463e-01,  1.3930e+00,\n",
       "         -1.0812e-01,  3.2396e-01, -7.5992e-01, -5.1354e-01,  4.7490e-01,\n",
       "         -1.4205e+00,  7.9690e-01],\n",
       "        [-7.0656e-02, -1.2355e-01, -1.1293e-01,  6.1331e-02,  4.2802e-02,\n",
       "          8.3257e-02,  5.2417e-01,  7.5815e-01,  2.8280e-01,  3.1151e-01,\n",
       "         -1.3089e+00, -3.9168e-01,  1.1445e-01,  1.8732e+00,  3.8899e-01,\n",
       "          6.6442e-02,  5.7316e-01, -5.4605e-01, -2.6184e-01,  5.5310e-01,\n",
       "         -8.1328e-01,  4.2103e-01],\n",
       "        [ 2.5003e-01,  7.0637e-01, -5.3174e-01, -3.5784e-01,  1.7663e-01,\n",
       "          4.7223e-02, -3.2004e-01, -5.0729e-01, -1.7137e-01, -1.4999e-01,\n",
       "          7.6822e-01, -5.1224e-01,  5.2470e-01, -7.0118e-01, -2.9068e-01,\n",
       "          4.4747e-02, -6.7415e-01,  9.0631e-01,  6.7800e-01, -6.8267e-01,\n",
       "         -1.1202e-01,  1.0088e-01],\n",
       "        [ 4.2058e-01,  7.8859e-01,  2.2280e-01, -1.9399e-01,  5.3329e-01,\n",
       "          2.4773e-01,  9.6869e-01,  5.7794e-01,  1.8011e-01,  6.5537e-01,\n",
       "         -4.3834e-01, -1.5316e-02,  5.0237e-02, -2.5056e-01,  1.3375e+00,\n",
       "         -4.8839e-02,  3.0206e-01, -7.1483e-01, -5.1734e-01,  4.4100e-01,\n",
       "         -1.3629e+00,  7.6355e-01],\n",
       "        [-2.2670e-01, -4.3891e-01,  2.4149e-01,  4.5628e-01, -6.2616e-01,\n",
       "          1.9131e-01, -4.6163e-01, -5.0455e-01,  7.1165e-02, -1.7242e-01,\n",
       "          4.1193e-01,  5.8110e-02,  2.8574e-01,  1.0424e-01, -1.3565e+00,\n",
       "          2.5638e-01, -5.5732e-01,  5.4869e-01,  9.7975e-02, -4.4850e-01,\n",
       "          5.5960e-01, -4.5925e-01],\n",
       "        [-3.6307e-02, -9.0322e-02, -7.0864e-02,  7.9531e-02,  1.3530e-02,\n",
       "          3.0111e-02,  4.7721e-01,  7.8193e-01,  2.7956e-01,  2.7387e-01,\n",
       "         -1.3261e+00, -4.1682e-01,  8.5024e-02,  1.8765e+00,  4.2454e-01,\n",
       "          3.9609e-02,  6.0857e-01, -5.9954e-01, -2.6344e-01,  5.9105e-01,\n",
       "         -8.3510e-01,  4.7389e-01],\n",
       "        [ 2.1569e-01,  6.7314e-01, -5.7381e-01, -3.7604e-01,  2.0590e-01,\n",
       "          1.0037e-01, -2.7308e-01, -5.3107e-01, -1.6813e-01, -1.1234e-01,\n",
       "          7.8548e-01, -4.8710e-01,  5.5412e-01, -7.0451e-01, -3.2623e-01,\n",
       "          7.1581e-02, -7.0956e-01,  9.5980e-01,  6.7960e-01, -7.2062e-01,\n",
       "         -9.0203e-02,  4.8018e-02],\n",
       "        [-5.3481e-02, -1.0693e-01, -9.1896e-02,  7.0431e-02,  2.8166e-02,\n",
       "          5.6684e-02,  5.0069e-01,  7.7004e-01,  2.8118e-01,  2.9269e-01,\n",
       "         -1.3175e+00, -4.0425e-01,  9.9736e-02,  1.8748e+00,  4.0676e-01,\n",
       "          5.3026e-02,  5.9087e-01, -5.7279e-01, -2.6264e-01,  5.7208e-01,\n",
       "         -8.2419e-01,  4.4746e-01],\n",
       "        [-5.0302e-02,  2.1081e-01,  8.1160e-01,  4.3101e-01,  5.1399e-01,\n",
       "          1.5349e-01,  3.7654e-02, -3.5837e-01, -2.7928e-02, -5.0958e-01,\n",
       "         -3.4221e-01, -4.9309e-01, -7.2650e-02, -3.9074e-01,  1.0392e-01,\n",
       "          2.1304e-01, -1.9382e-01, -3.6822e-01,  3.3629e-01,  7.7330e-01,\n",
       "          1.4914e-01, -9.3195e-02],\n",
       "        [ 2.7175e-02, -1.0890e+00, -6.2692e-01, -6.5601e-01,  4.3816e-01,\n",
       "          2.9835e-02, -3.3251e-01,  1.1145e+00, -4.9108e-01, -1.8277e-01,\n",
       "          2.6682e-01, -1.3150e-01, -6.9669e-01,  7.9870e-01,  1.3494e-01,\n",
       "         -4.8443e-01,  1.1153e-01, -7.8844e-02, -2.6041e-01, -8.6724e-01,\n",
       "          3.6216e-02,  5.1246e-01],\n",
       "        [-1.6169e-01, -3.9764e-01,  6.4333e-01,  2.8425e-01, -8.2279e-01,\n",
       "         -4.9402e-01, -5.5224e-01,  2.8904e-01, -3.3988e-01, -4.6298e-01,\n",
       "          5.8085e-01, -9.1847e-02, -5.0912e-01, -2.9155e-01, -5.7715e-01,\n",
       "         -2.3727e-01, -1.9954e-01, -5.0185e-01,  1.9696e-01, -2.6737e-01,\n",
       "          1.3899e-01, -4.7046e-01],\n",
       "        [ 4.3775e-01,  8.0520e-01,  2.4383e-01, -1.8489e-01,  5.1865e-01,\n",
       "          2.2116e-01,  9.4521e-01,  5.8983e-01,  1.7849e-01,  6.3655e-01,\n",
       "         -4.4697e-01, -2.7886e-02,  3.5525e-02, -2.4890e-01,  1.3553e+00,\n",
       "         -6.2256e-02,  3.1977e-01, -7.4157e-01, -5.1814e-01,  4.5997e-01,\n",
       "         -1.3738e+00,  7.8998e-01],\n",
       "        [-4.4133e-01,  2.4135e-01, -8.3751e-01,  1.7075e-01, -2.7163e-02,\n",
       "          1.6052e-01,  5.2950e-01,  5.4485e-02, -1.8463e-01,  2.1117e-01,\n",
       "         -4.6122e-01,  2.4733e-01,  1.0133e-01,  2.6276e-01,  5.6244e-01,\n",
       "         -2.6743e-01,  3.8294e-01,  6.9492e-02,  2.2039e-01,  7.5734e-02,\n",
       "         -3.2607e-01,  1.4325e-01],\n",
       "        [ 4.2058e-01,  7.8859e-01,  2.2280e-01, -1.9399e-01,  5.3329e-01,\n",
       "          2.4773e-01,  9.6869e-01,  5.7794e-01,  1.8011e-01,  6.5537e-01,\n",
       "         -4.3834e-01, -1.5316e-02,  5.0237e-02, -2.5056e-01,  1.3375e+00,\n",
       "         -4.8839e-02,  3.0206e-01, -7.1483e-01, -5.1734e-01,  4.4100e-01,\n",
       "         -1.3629e+00,  7.6355e-01],\n",
       "        [-2.1464e-01, -4.3575e-01,  2.4720e-01,  4.4451e-01, -6.3491e-01,\n",
       "          1.7685e-01, -4.7589e-01, -5.2195e-01,  5.5054e-02, -1.8185e-01,\n",
       "          4.2141e-01,  6.6605e-02,  2.7149e-01,  9.2102e-02, -1.3754e+00,\n",
       "          2.7931e-01, -5.5941e-01,  5.5787e-01,  9.5676e-02, -4.5596e-01,\n",
       "          5.8295e-01, -4.6271e-01],\n",
       "        [ 2.2774e-01,  6.7631e-01, -5.6810e-01, -3.8781e-01,  1.9715e-01,\n",
       "          8.5909e-02, -2.8733e-01, -5.4847e-01, -1.8424e-01, -1.2178e-01,\n",
       "          7.9497e-01, -4.7861e-01,  5.3987e-01, -7.1664e-01, -3.4506e-01,\n",
       "          9.4510e-02, -7.1165e-01,  9.6898e-01,  6.7730e-01, -7.2808e-01,\n",
       "         -6.6851e-02,  4.4557e-02],\n",
       "        [-1.6169e-01, -3.9764e-01,  6.4333e-01,  2.8425e-01, -8.2279e-01,\n",
       "         -4.9402e-01, -5.5224e-01,  2.8904e-01, -3.3988e-01, -4.6298e-01,\n",
       "          5.8085e-01, -9.1847e-02, -5.0912e-01, -2.9155e-01, -5.7715e-01,\n",
       "         -2.3727e-01, -1.9954e-01, -5.0185e-01,  1.9696e-01, -2.6737e-01,\n",
       "          1.3899e-01, -4.7046e-01],\n",
       "        [-2.0580e-03, -1.1088e+00, -6.5366e-01, -6.5334e-01,  4.6155e-01,\n",
       "          7.0868e-02, -2.9477e-01,  1.1201e+00, -4.7335e-01, -1.5451e-01,\n",
       "          2.6596e-01, -1.2743e-01, -6.6773e-01,  8.0917e-01,  1.3599e-01,\n",
       "         -4.9394e-01,  9.5916e-02, -6.1273e-02, -2.5731e-01, -8.7875e-01,\n",
       "          2.3770e-02,  4.8949e-01],\n",
       "        [ 2.6880e-01, -3.8718e-01, -1.0854e+00, -1.3427e-01,  4.4871e-01,\n",
       "          4.2805e-01, -2.3224e-01,  5.4707e-01,  9.8662e-02, -1.7017e-01,\n",
       "          4.8323e-01,  1.0907e-01,  3.8118e-01,  3.3499e-01,  3.8639e-01,\n",
       "         -3.3313e-01,  5.2314e-01,  9.3188e-01, -2.4096e-01, -5.7631e-01,\n",
       "         -7.3131e-02,  5.6771e-01],\n",
       "        [-3.7868e-01, -7.6431e-01,  2.2990e-01,  4.3205e-01, -1.1418e+00,\n",
       "         -3.4724e-01, -7.2815e-01, -5.3176e-01, -1.7201e-01, -2.1699e-01,\n",
       "          6.5655e-01, -7.5272e-02,  4.1635e-02, -2.1184e-01, -1.6538e+00,\n",
       "         -1.0663e-02, -3.8700e-01,  4.0837e-01,  2.2651e-01, -8.1672e-01,\n",
       "          7.4071e-01, -8.3294e-01],\n",
       "        [-1.3929e-01,  1.2786e-04,  6.5116e-01,  4.9737e-01,  3.2150e-01,\n",
       "          2.6077e-01,  9.8190e-03, -6.4887e-01, -5.9816e-02, -3.0688e-01,\n",
       "         -4.1849e-01, -6.7768e-01,  1.3161e-01, -1.4912e-01, -3.7672e-01,\n",
       "          3.5482e-01, -2.0735e-01, -3.8464e-02,  4.1330e-01,  4.2140e-01,\n",
       "          2.7222e-01, -1.2028e-01],\n",
       "        [-3.6307e-02, -9.0322e-02, -7.0864e-02,  7.9531e-02,  1.3530e-02,\n",
       "          3.0111e-02,  4.7721e-01,  7.8193e-01,  2.7956e-01,  2.7387e-01,\n",
       "         -1.3261e+00, -4.1682e-01,  8.5024e-02,  1.8765e+00,  4.2454e-01,\n",
       "          3.9609e-02,  6.0857e-01, -5.9954e-01, -2.6344e-01,  5.9105e-01,\n",
       "         -8.3510e-01,  4.7389e-01],\n",
       "        [ 2.3286e-01,  6.8975e-01, -5.5277e-01, -3.6694e-01,  1.9127e-01,\n",
       "          7.3796e-02, -2.9656e-01, -5.1918e-01, -1.6975e-01, -1.3117e-01,\n",
       "          7.7685e-01, -4.9967e-01,  5.3941e-01, -7.0284e-01, -3.0845e-01,\n",
       "          5.8164e-02, -6.9185e-01,  9.3306e-01,  6.7880e-01, -7.0164e-01,\n",
       "         -1.0111e-01,  7.4447e-02],\n",
       "        [ 2.7175e-02, -1.0890e+00, -6.2692e-01, -6.5601e-01,  4.3816e-01,\n",
       "          2.9835e-02, -3.3251e-01,  1.1145e+00, -4.9108e-01, -1.8277e-01,\n",
       "          2.6682e-01, -1.3150e-01, -6.9669e-01,  7.9870e-01,  1.3494e-01,\n",
       "         -4.8443e-01,  1.1153e-01, -7.8844e-02, -2.6041e-01, -8.6724e-01,\n",
       "          3.6216e-02,  5.1246e-01],\n",
       "        [ 3.8061e-03,  2.7638e-01,  7.5397e-01,  3.3742e-01,  4.3776e-01,\n",
       "          1.6909e-02,  9.6431e-03, -4.0047e-01, -7.5988e-02, -5.6793e-01,\n",
       "         -4.2928e-01, -5.2296e-01, -1.2491e-01, -3.3601e-01,  4.5408e-02,\n",
       "          2.5659e-01, -1.7425e-01, -4.4656e-01,  3.6246e-01,  7.3774e-01,\n",
       "          8.6488e-02, -2.8959e-02],\n",
       "        [ 3.8002e-01,  5.7298e-01, -6.4487e-02, -3.1787e-01,  2.9966e-03,\n",
       "         -5.3475e-01,  3.1231e-01, -7.0913e-01,  2.4513e-01,  3.0330e-01,\n",
       "          3.3697e-01,  8.2358e-01,  1.7396e-01, -1.6560e+00,  1.2211e-01,\n",
       "         -2.2117e-02, -4.3578e-02,  2.3455e-01, -5.4797e-01,  2.9790e-02,\n",
       "          1.7804e-01, -5.0465e-01],\n",
       "        [ 4.7718e-01,  9.4038e-01,  3.0635e-01, -8.8849e-02,  7.7629e-01,\n",
       "          5.1856e-01,  8.6800e-01,  5.3197e-01,  3.8551e-01,  5.4500e-01,\n",
       "         -3.3449e-01,  2.0986e-01,  2.0391e-01, -2.0166e-01,  1.3679e+00,\n",
       "          2.0025e-01,  2.1200e-01, -4.3856e-01, -7.9300e-01,  7.9089e-01,\n",
       "         -1.1850e+00,  9.1585e-01]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test @ lr.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test-set took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in X_test]\n",
    "y_test_2 = [y.detach().numpy() for y in y_test]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can't add vectors of different sizes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[397], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m correct \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_test)\n\u001b[0;32m---> 21\u001b[0m encrypted_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mencrypted_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43meelr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_x_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m diff_accuracy \u001b[38;5;241m=\u001b[39m  encrypted_accuracy\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifference between plain and encrypted accuracies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[397], line 7\u001b[0m, in \u001b[0;36mencrypted_evaluation\u001b[0;34m(model, enc_x_test, y_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m enc_x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(enc_x_test, y_test):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# encrypted evaluation\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# plain comparison\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     out \u001b[38;5;241m=\u001b[39m enc_out\u001b[38;5;241m.\u001b[39mdecrypt()\n",
      "Cell \u001b[0;32mIn[291], line 17\u001b[0m, in \u001b[0;36mEncryptedLR.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[291], line 13\u001b[0m, in \u001b[0;36mEncryptedLR.forward\u001b[0;34m(self, enc_x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, enc_x):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# We don't need to perform sigmoid as this model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# will only be used for evaluation, and the label\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# can be deduced without applying sigmoid\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[43menc_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enc_out\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-andrew.cmu.edu/5. Coursework/S24 95-878 Engineering Privacy/homomorphic-ml-project/.venv/lib/python3.10/site-packages/tenseal/tensors/abstract_tensor.py:107\u001b[0m, in \u001b[0;36mAbstractTensor.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstractTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-andrew.cmu.edu/5. Coursework/S24 95-878 Engineering Privacy/homomorphic-ml-project/.venv/lib/python3.10/site-packages/tenseal/tensors/ckksvector.py:92\u001b[0m, in \u001b[0;36mCKKSVector.add\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCKKSVector\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_operand(other, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap(result)\n",
      "\u001b[0;31mValueError\u001b[0m: can't add vectors of different sizes"
     ]
    }
   ],
   "source": [
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time()\n",
    "    \n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        # encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        # plain comparison\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(out - y) < 0.5:\n",
    "            correct += 1\n",
    "    \n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(X_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f\"Accuracy: {correct}/{len(X_test)} = {correct / len(X_test)}\")\n",
    "    return correct / len(X_test)\n",
    "    \n",
    "\n",
    "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test_2)\n",
    "diff_accuracy =  encrypted_accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Two main ideas:\n",
    "    1. It just seems fun to dissect and try to understand what's happening in the black box. I used to be very \"skeptical\" about these black box system and thought there was no way to open it up - but it seems we are making small steps. \n",
    "    2. Technical inventions would push governance (managing short term / actual risks)\n",
    "\n",
    "- Output: really, just do something practical and small scale research. \n",
    "\n",
    "\n",
    "- revised commitments\n",
    "- discuss, figure out a research question\n",
    "- form groups\n",
    "- spring break -> do projects \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
