{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept - ML with Homomorphic Encryption \n",
    "\n",
    "Basic idea is to try out very simple neural network in Torch to be converted into an equivalent network that processes homomorphic encrpyted data. \n",
    "In this example, we are using two libraries: TenSEAL by OpenMined and Concrete-ML by Zama. \n",
    "\n",
    "**Dataset used**: Adult income dataset \n",
    "https://www.kaggle.com/datasets/wenruliu/adult-income-dataset \n",
    "\n",
    "**Model architecture**:\n",
    "- Linear (256, 15) // 256 neurons, 15 input features\n",
    "- ReLU \n",
    "- Linear (2, 256)  // 2 output class\n",
    "\n",
    "--- \n",
    "Version Log and Todo:\n",
    "\n",
    "- Need to recheck on Tenseal context to perform multiple matrix multiplications\n",
    "---\n",
    "\n",
    "This Proof of Concept is largely influenced by \n",
    "\n",
    "https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb#:~:text=Tutorial,-1%20%2D%20Training%20and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tenseal as ts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from concrete.ml.torch.compile import compile_torch_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".data/adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "      def __init__(self, df, train=True, scaler=None, one_hot_encoder=None):\n",
    "          # Make a copy of the dataframe to avoid modifying the original\n",
    "          cdf = df.copy()\n",
    "\n",
    "          # Handle missing values\n",
    "          cdf = cdf.replace('?', np.nan)\n",
    "\n",
    "          # Fill missing values with the most common value for categorical features\n",
    "          categorical_cols = ['workclass', 'occupation', 'native-country']\n",
    "          for col in categorical_cols:\n",
    "              cdf[col] = cdf[col].fillna(cdf[col].mode()[0])\n",
    "\n",
    "          # Process target column first (before one-hot encoding)\n",
    "          if train:\n",
    "              cdf['income'] = cdf['income'].map({'>50K': 1, '<=50K': 0})\n",
    "              target = cdf['income'].values\n",
    "              cdf.drop('income', axis=1, inplace=True)\n",
    "          else:\n",
    "              # For test set\n",
    "              if 'income' in cdf.columns:\n",
    "                  cdf['income'] = cdf['income'].map({'>50K': 1, '<=50K': 0})\n",
    "                  target = cdf['income'].values\n",
    "                  cdf.drop('income', axis=1, inplace=True)\n",
    "              else:\n",
    "                  target = None\n",
    "\n",
    "          # Extract numeric and categorical columns\n",
    "          numeric_cols = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss',\n",
    "  'hours-per-week']\n",
    "          cat_cols = [col for col in cdf.columns if col not in numeric_cols]\n",
    "\n",
    "          # Normalize numeric columns\n",
    "          if train:\n",
    "              # If training data, fit a new scaler\n",
    "              self.scaler = StandardScaler()\n",
    "              cdf[numeric_cols] = self.scaler.fit_transform(cdf[numeric_cols])\n",
    "          else:\n",
    "              # If test data, use the provided scaler\n",
    "              if scaler is not None:\n",
    "                  cdf[numeric_cols] = scaler.transform(cdf[numeric_cols])\n",
    "\n",
    "          # One-hot encode categorical features\n",
    "          if train:\n",
    "              # Save original categorical data for reference\n",
    "              self.categorical_data = cdf[cat_cols].copy()\n",
    "              # Apply one-hot encoding\n",
    "              cdf_encoded = pd.get_dummies(cdf, columns=cat_cols)\n",
    "              # Save column names for future reference\n",
    "              self.encoded_columns = cdf_encoded.columns\n",
    "              processed_data = cdf_encoded\n",
    "          else:\n",
    "              # For test data, ensure we have the same columns as training\n",
    "              if one_hot_encoder is not None:\n",
    "                  # One-hot encode the categorical columns\n",
    "                  test_encoded = pd.get_dummies(cdf, columns=cat_cols)\n",
    "\n",
    "                  # Add missing columns that are in training but not in test\n",
    "                  for col in one_hot_encoder:\n",
    "                      if col not in test_encoded.columns:\n",
    "                          test_encoded[col] = 0\n",
    "\n",
    "                  # Ensure columns are in the same order as training\n",
    "                  processed_data = test_encoded[one_hot_encoder]\n",
    "\n",
    "          # Convert to numpy array\n",
    "          self.data = processed_data.values.astype('float32')\n",
    "          self.target = target\n",
    "          self.nfeatures = self.data.shape[1]\n",
    "          self.train = train\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.data)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          if self.target is not None:\n",
    "              return self.data[idx], self.target[idx]\n",
    "          else:\n",
    "              return self.data[idx], np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE  = 64\n",
    "TRAIN_BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (39073, 105)\n",
      "Test data shape: (9769, 105)\n",
      "Number of features: 105\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create training dataset first\n",
    "train_dataset = Dataset(train_df, train=True)\n",
    "\n",
    "# Create test dataset using the same scaler and one-hot encoding as training\n",
    "test_dataset = Dataset(test_df, train=False,\n",
    "                    scaler=train_dataset.scaler,\n",
    "                    one_hot_encoder=train_dataset.encoded_columns)\n",
    "\n",
    "# Create data loaders\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Verify shapes match (features should be same dimension)\n",
    "print(f\"Training data shape: {train_dataset.data.shape}\")\n",
    "print(f\"Test data shape: {test_dataset.data.shape}\")\n",
    "print(f\"Number of features: {train_dataset.nfeatures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3368,  0.2640,  1.1367,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.4825,  0.0210,  1.5256,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.0655,  2.9288,  1.1367,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.8469, -0.3966, -0.0298,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.9926,  0.0554, -0.4187,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.5027,  1.6702, -0.4187,  ...,  1.0000,  0.0000,  0.0000]]),\n",
       " tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "         0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "         0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "         1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 105])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 105])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(testloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for mps / cuda as its a very simple network\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier(train_dataset.nfeatures).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "  loss: 0.6763036251068115\n",
      "  accuracy: 0.3719448212320528\n",
      "epoch: 2\n",
      "  loss: 0.625588059425354\n",
      "  accuracy: 0.7778773065799913\n",
      "epoch: 3\n",
      "  loss: 0.5257165431976318\n",
      "  accuracy: 0.7813579709774012\n",
      "epoch: 4\n",
      "  loss: 0.4393138885498047\n",
      "  accuracy: 0.7922094540987382\n",
      "epoch: 5\n",
      "  loss: 0.4221590757369995\n",
      "  accuracy: 0.8093824380006654\n",
      "epoch: 6\n",
      "  loss: 0.366595596075058\n",
      "  accuracy: 0.8234330611931513\n",
      "epoch: 7\n",
      "  loss: 0.3580872118473053\n",
      "  accuracy: 0.8302664243851253\n",
      "epoch: 8\n",
      "  loss: 0.39628124237060547\n",
      "  accuracy: 0.8355642003429478\n",
      "epoch: 9\n",
      "  loss: 0.3669053912162781\n",
      "  accuracy: 0.8376372431090523\n",
      "epoch: 10\n",
      "  loss: 0.3955754339694977\n",
      "  accuracy: 0.8398126583574336\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    \n",
    "    classifier.train()\n",
    "    \n",
    "    for i, (data, target) in enumerate((dataloader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = classifier(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1)\n",
    "        running_correct += (pred == target).sum().item()\n",
    "        running_total += target.size(0)\n",
    "    \n",
    "    print(f\"epoch: {epoch+1}\")\n",
    "    print(f\"  loss: {loss.item()}\")\n",
    "    print(f\"  accuracy: {running_correct / running_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Homomorphic Encryption with Concrete ML\n",
    "\n",
    "Homomorphic Encryption (HE) allows computation on encrypted data without decrypting it first. This preserves privacy while still enabling machine learning inference.\n",
    "\n",
    "In this section, we'll explore how to:\n",
    "1. Compile our PyTorch model with Concrete ML\n",
    "2. Perform inference in simulation mode to verify accuracy\n",
    "3. Execute inference in FHE mode to measure performance\n",
    "\n",
    "### Step 1: Model Compilation\n",
    "\n",
    "Here we compile our trained PyTorch model to be compatible with FHE operations. This process involves:\n",
    "- Quantizing the model (reducing precision to work with integers)\n",
    "- Creating an FHE-compatible circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<concrete.ml.quantization.quantized_module.QuantizedModule at 0x327603820>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a representative input for compilation\n",
    "torch_input = torch.randn(32, 105)\n",
    "\n",
    "# Compile the PyTorch model\n",
    "# - n_bits=6: Set quantization bits for weights and activations\n",
    "# - rounding_threshold_bits: Controls precision during computation\n",
    "quantized_module = compile_torch_model(\n",
    "    classifier.to('cpu'),  # Our trained model\n",
    "    torch_input,           # Sample input for quantization and compilation\n",
    "    n_bits=6,              # Bit precision for quantization\n",
    "    rounding_threshold_bits={\"n_bits\": 6, \"method\": \"approximate\"}\n",
    ")\n",
    "\n",
    "quantized_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Simulation Mode Testing\n",
    "\n",
    "In this step, we'll run inference in simulation mode (`fhe=\"simulate\"`) to:\n",
    "- Verify the model works with encrypted data\n",
    "- Measure the accuracy impact of quantization\n",
    "- Test on the first batch from our test dataset\n",
    "\n",
    "This simulates FHE operations without actually encrypting data, which is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model prediction: 0\n",
      "Actual target: 0\n",
      "\n",
      "Simulated FHE prediction: 0\n",
      "Prediction matches original: True\n",
      "Both match actual target: True\n",
      "\n",
      "Original output: [[ 1.5171748 -1.2382808]]\n",
      "Dequantized output: [[ 1.45416066 -1.23776891]]\n",
      "Quantization impact (difference): [[ 0.06301418 -0.00051186]]\n",
      "CPU times: user 1min 36s, sys: 2.33 s, total: 1min 39s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Get a single test example\n",
    "data, target = next(iter(testloader))\n",
    "data = data[0].unsqueeze(0)\n",
    "target = target[0]\n",
    "\n",
    "# Original PyTorch model prediction (baseline)\n",
    "with torch.no_grad():\n",
    "    original_output = classifier(data)\n",
    "    original_pred = original_output.argmax().item()\n",
    "\n",
    "print(f\"Original model prediction: {original_pred}\")\n",
    "print(f\"Actual target: {target.item()}\")\n",
    "\n",
    "# Quantize the input\n",
    "x_test_q = quantized_module.quantize_input(data.numpy())\n",
    "\n",
    "# Run inference in simulate mode (simulates FHE behavior without encryption)\n",
    "y_pred_simulate = quantized_module.quantized_forward(x_test_q, fhe=\"execute\")\n",
    "\n",
    "# Dequantize the output to get back to original scale\n",
    "y_pred_dequantized = quantized_module.dequantize_output(y_pred_simulate)\n",
    "simulate_pred = np.argmax(y_pred_dequantized)\n",
    "\n",
    "print(f\"\\nSimulated FHE prediction: {simulate_pred}\")\n",
    "print(f\"Prediction matches original: {original_pred == simulate_pred}\")\n",
    "print(f\"Both match actual target: {original_pred == target.item() and simulate_pred == target.item()}\")\n",
    "\n",
    "# Show quantized and dequantized values to observe any precision loss\n",
    "print(f\"\\nOriginal output: {original_output.detach().numpy()}\")\n",
    "print(f\"Dequantized output: {y_pred_dequantized}\")\n",
    "print(f\"Quantization impact (difference): {original_output.detach().numpy() - y_pred_dequantized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2663, -1.4850, -0.4187, -0.1445, -0.2197, -0.0344,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_BATCH_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEST_BATCH_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get a single test sample (using only the first item in the batch)\n",
    "rand_id = np.random.randint(1, TEST_BATCH_SIZE)\n",
    "\n",
    "data, target = next(iter(testloader))\n",
    "data_single = data[rand_id].unsqueeze(0)  # Take just the first sample and keep batch dimension\n",
    "target_single = target[rand_id].item()    # Get the actual target value\n",
    "\n",
    "# Quantize the input\n",
    "x_test_q = quantized_module.quantize_input(data_single.numpy())\n",
    "\n",
    "# Run inference in simulation mode\n",
    "print(\"Running in FHE simulate mode...\")\n",
    "y_pred_simulate = quantized_module.quantized_forward(x_test_q, fhe=\"simulate\")\n",
    "\n",
    "# Dequantize the output\n",
    "y_pred_dequantized = quantized_module.dequantize_output(y_pred_simulate)\n",
    "simulate_pred = np.argmax(y_pred_dequantized)\n",
    "\n",
    "print(f\"\\nFHE simulation prediction: {simulate_pred}\")\n",
    "print(f\"Actual target: {target_single}\")\n",
    "print(f\"Prediction matches target: {simulate_pred == target_single}\")\n",
    "\n",
    "# Show the output\n",
    "print(f\"\\nFHE output (dequantized): {y_pred_dequantized}\")\n",
    "\n",
    "# Compare with original model prediction\n",
    "with torch.no_grad():\n",
    "    original_output = classifier(data_single)\n",
    "    original_pred = original_output.argmax().item()\n",
    "    \n",
    "print(f\"Original model prediction: {original_pred}\")\n",
    "print(f\"Match between FHE simulation and original: {original_pred == simulate_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FHE Execution Results:\n",
      "Prediction: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])\n",
      "Actual target: tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n",
      "Batch accuracy: 0.8750 (56/64 correct)\n",
      "\n",
      "Original Model Results:\n",
      "Original model predictions: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])\n",
      "Original model accuracy: 0.8750 (56/64 correct)\n",
      "Agreement between FHE and original model: 64/64 samples\n",
      "\n",
      "Classifier Model Results:\n",
      "Classifier predictions: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])\n",
      "Classifier accuracy: 0.8750 (56/64 correct)\n",
      "Agreement between FHE and classifier: 64/64 samples\n",
      "CPU times: user 2.68 s, sys: 5.51 s, total: 8.19 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get a test batch\n",
    "data, target = next(iter(testloader))\n",
    "\n",
    "# Run prediction with original PyTorch model\n",
    "with torch.no_grad():\n",
    "    original_output = classifier(data)  # Using the original PyTorch model\n",
    "    original_pred = original_output.argmax(dim=1)\n",
    "    original_accuracy = accuracy_score(target.numpy(), original_pred.numpy())\n",
    "\n",
    "# Quantize the input for FHE compatibility\n",
    "x_test_q = quantized_module.quantize_input(data.numpy())\n",
    "\n",
    "# Run the forward pass in simulated FHE mode\n",
    "y_pred_fhe = quantized_module.quantized_forward(x_test_q, fhe=\"simulate\")\n",
    "\n",
    "# Dequantize the output back to floating point\n",
    "y_pred_fhe_dequantized = quantized_module.dequantize_output(y_pred_fhe)\n",
    "\n",
    "# Get class predictions\n",
    "fhe_pred = torch.tensor(np.argmax(y_pred_fhe_dequantized, axis=1))\n",
    "\n",
    "# Calculate batch accuracy\n",
    "accuracy = accuracy_score(target.numpy(), fhe_pred.numpy())\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nFHE Execution Results:\")\n",
    "print(f\"Prediction: {fhe_pred}\")\n",
    "print(f\"Actual target: {target}\")\n",
    "print(f\"Batch accuracy: {accuracy:.4f} ({torch.sum(fhe_pred == target).item()}/{len(target)} correct)\")\n",
    "\n",
    "# Show the output (dequantized values)\n",
    "# print(f\"\\nFHE output (dequantized):\")\n",
    "# print(f\"{y_pred_fhe_dequantized}\")\n",
    "\n",
    "# Compare with the original model\n",
    "print(f\"\\nOriginal Model Results:\")\n",
    "print(f\"Original model predictions: {original_pred}\")\n",
    "print(f\"Original model accuracy: {original_accuracy:.4f} ({torch.sum(original_pred == target).item()}/{len(target)} correct)\")\n",
    "print(f\"Agreement between FHE and original model: {torch.sum(fhe_pred == original_pred).item()}/{len(fhe_pred)} samples\")\n",
    "\n",
    "# Results using the classifier (if different from model)\n",
    "print(f\"\\nClassifier Model Results:\")\n",
    "with torch.no_grad():\n",
    "    classifier_output = classifier(data)\n",
    "    classifier_pred = classifier_output.argmax(dim=1)\n",
    "    classifier_accuracy = accuracy_score(target.numpy(), classifier_pred.numpy())\n",
    "    \n",
    "print(f\"Classifier predictions: {classifier_pred}\")\n",
    "print(f\"Classifier accuracy: {classifier_accuracy:.4f} ({torch.sum(classifier_pred == target).item()}/{len(target)} correct)\")\n",
    "print(f\"Agreement between FHE and classifier: {torch.sum(fhe_pred == classifier_pred).item()}/{len(fhe_pred)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: FHE Execution Mode Performance\n",
    "\n",
    "Now we'll run the model in full FHE execution mode (`fhe=\"execute\"`). This performs actual homomorphic encryption operations:\n",
    "1. Encrypts the input\n",
    "2. Performs computation on encrypted data\n",
    "3. Decrypts the result\n",
    "\n",
    "We'll use `%%time` magic to measure performance, as FHE operations are typically much slower than plaintext operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get a single test sample (using only the first item in the batch)\n",
    "data, target = next(iter(testloader))\n",
    "data_single = data[0].unsqueeze(0)  # Take just the first sample and keep batch dimension\n",
    "target_single = target[0].item()    # Get the actual target value\n",
    "\n",
    "# Quantize the input\n",
    "x_test_q = quantized_module.quantize_input(data_single.numpy())\n",
    "\n",
    "# Run inference in full FHE execution mode\n",
    "print(\"Running in FHE execute mode (this may take some time)...\")\n",
    "y_pred_fhe = quantized_module.quantized_forward(x_test_q, fhe=\"execute\")\n",
    "\n",
    "# Dequantize the output\n",
    "y_pred_fhe_dequantized = quantized_module.dequantize_output(y_pred_fhe)\n",
    "fhe_pred = np.argmax(y_pred_fhe_dequantized)\n",
    "\n",
    "print(f\"\\nFHE execution prediction: {fhe_pred}\")\n",
    "print(f\"Actual target: {target_single}\")\n",
    "print(f\"Prediction matches target: {fhe_pred == target_single}\")\n",
    "\n",
    "# Show the output\n",
    "print(f\"\\nFHE output (dequantized): {y_pred_fhe_dequantized}\")\n",
    "\n",
    "# Compare with simulation results\n",
    "print(f\"\\nComparing with previous results:\")\n",
    "with torch.no_grad():\n",
    "    original_output = classifier(data_single)\n",
    "    original_pred = original_output.argmax().item()\n",
    "    \n",
    "print(f\"Original model prediction: {original_pred}\")\n",
    "print(f\"FHE execution matches original model: {fhe_pred == original_pred}\")\n",
    "\n",
    "# If y_pred_simulate was stored from the previous cell\n",
    "try:\n",
    "    y_pred_simulate_dequantized = quantized_module.dequantize_output(y_pred_simulate)\n",
    "    simulate_pred = np.argmax(y_pred_simulate_dequantized)\n",
    "    print(f\"FHE execution matches FHE simulation: {fhe_pred == simulate_pred}\")\n",
    "except NameError:\n",
    "    print(\"No simulate results available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Batch Processing in Simulation Mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Original input shape: torch.Size([1, 105])\n",
      "   Quantized input: [[ 10 -16  -6  -3  -4  -2  -2  -2  -2   7  -2  -2  -2  -2  -2  -2  -2  -2\n",
      "   -2  -2  -2  -2  -2  -2  -2   7  -2  -2  -2  -2   7  -2  -2  -2  -2  -2\n",
      "   -2  -2  -2  -2  -2  -2  -2  -2   7  -2  -2  -2  -2  -2  -2  -2  -2  -2\n",
      "   -2   7  -2  -2  -2  -2  -2   7   7  -2  -2  -2  -2  -2  -2  -2  -2  -2\n",
      "   -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2\n",
      "   -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2   7  -2  -2]]\n",
      "   Quantized input shape: (1, 105)\n",
      "\n",
      "2. Input encrypted: <class 'concrete.fhe.compilation.value.Value'>\n",
      "   First few bytes of encrypted data: 0100000057010000030000000000000000000000000003000800000000000100f80400000100010008050000010001000100...\n",
      "\n",
      "3. Running model on encrypted data...\n",
      "   Model execution complete\n",
      "   Output is still encrypted: <class 'concrete.fhe.compilation.value.Value'>\n",
      "\n",
      "4. Decrypted result (still quantized): [[ 5228 -5273]]\n",
      "\n",
      "5. Final dequantized output: [[ 1.95626007 -2.17794744]]\n",
      "   Predicted class: 0\n",
      "   Actual class: 0\n",
      "\n",
      "6. Direct model output (without FHE): [[ 2.0050619 -2.2394466]]\n",
      "   Direct predicted class: 0\n",
      "   Accuracy preserved: True\n"
     ]
    }
   ],
   "source": [
    "# Detailed breakdown of the FHE pipeline steps\n",
    "\n",
    "# Get a sample input\n",
    "data, target = next(iter(testloader))\n",
    "\n",
    "# Step 1: Quantize the input (convert floats to integers)\n",
    "# This is necessary since FHE works with integers\n",
    "q_input = quantized_module.quantize_input(data.numpy())\n",
    "print(f\"1. Original input shape: {data.shape}\")\n",
    "print(f\"   Quantized input: {q_input}\")\n",
    "print(f\"   Quantized input shape: {q_input.shape}\")\n",
    "print()\n",
    "\n",
    "# Step 2: Encrypt the quantized input\n",
    "# The input is now encrypted and cannot be read without the decryption key\n",
    "q_input_enc = quantized_module.fhe_circuit.encrypt(q_input)\n",
    "print(f\"2. Input encrypted: {type(q_input_enc)}\")\n",
    "print(f\"   First few bytes of encrypted data: {q_input_enc.serialize().hex()[:100]}...\")\n",
    "print()\n",
    "\n",
    "# Step 3: Execute the model on encrypted data\n",
    "# The model performs calculations without ever decrypting the data\n",
    "print(\"3. Running model on encrypted data...\")\n",
    "q_y_enc = quantized_module.fhe_circuit.run(q_input_enc)\n",
    "print(f\"   Model execution complete\")\n",
    "print(f\"   Output is still encrypted: {type(q_y_enc)}\")\n",
    "print()\n",
    "\n",
    "# Step 4: Decrypt the result (still quantized)\n",
    "# Now we decrypt to get back the quantized prediction\n",
    "q_y = quantized_module.fhe_circuit.decrypt(q_y_enc)\n",
    "print(f\"4. Decrypted result (still quantized): {q_y}\")\n",
    "print()\n",
    "\n",
    "# Step 5: Dequantize the result (convert back to floating point)\n",
    "# Convert from integer back to float for final prediction\n",
    "y_final = quantized_module.dequantize_output(q_y)\n",
    "print(f\"5. Final dequantized output: {y_final}\")\n",
    "print(f\"   Predicted class: {np.argmax(y_final)}\")\n",
    "print(f\"   Actual class: {target.item()}\")\n",
    "print()\n",
    "\n",
    "# Compare with direct model prediction (without FHE)\n",
    "with torch.no_grad():\n",
    "    direct_output = classifier(data).numpy()\n",
    "print(f\"6. Direct model output (without FHE): {direct_output}\")\n",
    "print(f\"   Direct predicted class: {np.argmax(direct_output)}\")\n",
    "print(f\"   Accuracy preserved: {np.argmax(direct_output) == np.argmax(y_final)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tenseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 105])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model[0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tenseal Context \n",
    "\n",
    "# parameters\n",
    "poly_mod_degree = 16384\n",
    "coeff_mod_bit_sizes = [60, 40, 40, 60]\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 40\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# poly_mod_degree = 16384  # Increased for more precision\n",
    "# coeff_mod_bit_sizes = [50, 30, 30, 30, 50]  # More conservative chain\n",
    "# scale = 2 ** 30  # Matched with middle layers\n",
    "\n",
    "# # create TenSEALContext\n",
    "# ctx_eval = ts.context(\n",
    "#     scheme=ts.SCHEME_TYPE.CKKS,\n",
    "#     poly_modulus_degree=poly_mod_degree,\n",
    "#     coeff_mod_bit_sizes=coeff_mod_bit_sizes\n",
    "# )\n",
    "# ctx_eval.global_scale = scale\n",
    "# ctx_eval.generate_galois_keys()\n",
    "\n",
    "# ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree = 16384, coeff_mod_bit_sizes = [60, 60, 60, 60, 60, 60])\n",
    "# ctx_eval.generate_galois_keys()\n",
    "# ctx_eval.global_scale = 2**25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5149, 2.5149]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing \n",
    "a = torch.rand((1, 5))\n",
    "b = torch.ones((5, 2))\n",
    "\n",
    "enc_a = ts.ckks_tensor(ctx_eval, a)\n",
    "enc_b = ts.ckks_tensor(ctx_eval, b)\n",
    "\n",
    "(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5149, 2.5149]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor((enc_a @ enc_b).decrypt().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tenseal.tensors.ckkstensor.CKKSTensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.5149, 2.5149]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(enc_a))\n",
    "print(type(b))\n",
    "torch.tensor((enc_a @ b).decrypt().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x, _ = next(iter(testloader))\n",
    "enc_x = ts.ckks_tensor(ctx_eval, x.tolist())\n",
    "\n",
    "print(x)\n",
    "print(type(enc_x))\n",
    "print(type(classifier.model[0].weight.data))\n",
    "enc_x @ (classifier.model[0].weight.data.cpu().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "enc_x.scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate a forward pass - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "w_ = classifier.model[0].weight.data.cpu().T\n",
    "w_.to(torch.float8_e4m3fn)\n",
    "xl = enc_x @ (classifier.model[0].weight.data.cpu().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Stuck at this point, scale out of bounds\n",
    "\n",
    "w2_ = classifier.model[2].weight.data.cpu().T\n",
    "w2_.to(torch.float8_e5m2)\n",
    "\n",
    "xl @ (w2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Code in this cell and after did not consider RELU yet, so need to adapt (hardcoded 2 layers)\n",
    "class EncryptedClassifier:\n",
    "    \n",
    "    def __init__(self, unencrypted_model):\n",
    "        \n",
    "        # assuming same architecture\n",
    "        self.w1 = unencrypted_model.model[0].weight.data.cpu() # [256, 15]\n",
    "        self.b1 = unencrypted_model.model[0].bias.data.cpu()  # [256]\n",
    "        \n",
    "        self.w2 = unencrypted_model.model[2].weight.data.cpu()  # [2, 256]\n",
    "        self.b2 = unencrypted_model.model[2].bias.data.cpu()  # [2]\n",
    "        \n",
    "\n",
    "    # def forward(self, enc_x):\n",
    "    #     # assume encrypted input\n",
    "        \n",
    "    #     # enc_x would be in the shape of [1, 15]\n",
    "    #     # while w1 is in shape [256, 15] \n",
    "    #     results = [ ]\n",
    "    #     for row in self.w1.T:\n",
    "    #         part_result = enc_x @ row  # Dot product instead of full matrix mult\n",
    "    #         results.append(part_result) # a little tricky here since the individual items are in form ckks_tensor, how to stack them (?)\n",
    "        \n",
    "    #     # Combine results\n",
    "    #     x = torch.stack(results)\n",
    "    #     x = enc_x @ self.w1.T \n",
    "    #     x = x @ self.w2.T \n",
    "        \n",
    "    #     return x\n",
    " \n",
    " \n",
    "    ## apparently, the context need to be adjusted so we can do matmul twice.\n",
    "    ## it keeps making scale out of bounds error. To be researched\n",
    "    def forward(self, enc_x):\n",
    "        # assume encrypted input\n",
    "        \n",
    "        # enc_x would be in the shape of [1, 15]\n",
    "        # while w1 is in shape [256, 15] \n",
    "        \n",
    "        x = enc_x @ self.w1.T \n",
    "        # need relu, but not sure how\n",
    "        x = x @ self.w2.T \n",
    "        \n",
    "        return x        \n",
    "        \n",
    "        \n",
    "        # enc_z = []\n",
    "        \n",
    "        # # calculate dot product of each neuron\n",
    "        # for i in range(self.w1.shape[0]):               # 256 times\n",
    "        #     # print(f\"forward 1 - {i}\")\n",
    "        #     z = enc_x.dot(self.w1[i, :])    # dot product input x neuron weights\n",
    "        #     z += self.b1[i]                 # add bias value \n",
    "        #     enc_z.append(z)         # add the result\n",
    "            \n",
    "        # # enc_z should be an array of [256, 1]\n",
    "        # print(type(enc_z[0]))\n",
    "        # print(type(enc_z))\n",
    "        \n",
    "        # # redo for second layer\n",
    "        # enc_z2 = []\n",
    "        # # calculate dot product of each neuron\n",
    "        # for i in range(self.w2.shape[0]):   # 2 times\n",
    "        #     print(f\"forward 2 - {i}\")\n",
    "        #     z = enc_z.dot(self.w2[i, :])    # dot product input x neuron weights\n",
    "        #     z += self.b2[i]                 # add bias value \n",
    "        #     enc_z2.append(enc_z2)         # add the result\n",
    "                  \n",
    "        # # enc_z should be an array of [2, 1]\n",
    "        # return enc_z\n",
    "\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "        \n",
    "\n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.w1 = ts.ckks_vector(context, self.w1)\n",
    "        self.b1 = ts.ckks_vector(context, self.b1)\n",
    "        \n",
    "        \n",
    "        self.w2 = ts.ckks_vector(context, self.w2)\n",
    "        self.b2 = ts.ckks_vector(context, self.b2)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.w1 = self.w1.decrypt()\n",
    "        self.b1 = self.b1.decrypt()\n",
    "        \n",
    "        self.w2 = self.w2.decrypt()\n",
    "        self.b2 = self.b2.decrypt()\n",
    "        \n",
    "\n",
    "encCls = EncryptedClassifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data, target = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i, (data, target) in enumerate((testloader)):\n",
    "    print(f\"Instance {i}\")\n",
    "    \n",
    "    x = data[0]\n",
    "    print(f\"\\t input tensor: {x}\")\n",
    "    \n",
    "    enc_x = ts.ckks_tensor(ctx_eval, [x])\n",
    "    print(f\"\\t ckks enc tensor: {enc_x}\")\n",
    "    \n",
    "    # encrypted evaluation\n",
    "    enc_out = encCls(enc_x)\n",
    "    print(f\"\\t forward output tensor: {enc_out}\")\n",
    "    \n",
    "    # plain comparison\n",
    "    out = enc_out.decrypt()\n",
    "    print(f\"\\t decrypted output: {torch.tensor(out.tolist())}\")\n",
    "    \n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
